"""文本预处理工具模块

此模块提供了文本处理的辅助函数，主要功能包括：
- 文本清理：移除HTML标签
- 标点符号处理：移除或替换特殊字符
- 文本分词：将文本分割成词语列表
- 文本标准化：转换为小写形式
"""
import re

def tokenize(text):
    """文本分词和清理函数
    
    对输入文本进行以下处理：
    1. 移除HTML标签
    2. 移除标点符号和特殊字符
    3. 分词并转换为小写形式
    
    参数:
        text (str): 待处理的原始文本
        
    返回:
        List[str]: 处理后的词语列表
    """
    # 定义需要过滤的特殊字符列表
    filters = [
        "!", '"', "#", "$", "%", "&", "\(", "\)", "\*", "\+", ",", "-", "\.", "/", ":", ";", "<", "=", ">", "\?", "@", "\[", "\\", "\]", "^", "_", "`", "\{", "\|", "\}", "~", "\t", "\n", "\x97", "\x96", """, """,
    ]
    # 移除HTML标签，将其替换为空格
    text = re.sub("<.*?>", " ", text, flags=re.S)
    # 移除所有特殊字符，将其替换为空格
    text = re.sub("|".join(filters), " ", text, flags=re.S)
    # 分词，去除首尾空格，转换为小写
    return [i.strip().lower() for i in text.split()]

